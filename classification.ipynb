{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19438453-42e8-495d-93a5-37197f9da9c1",
   "metadata": {},
   "source": [
    " # Quick Classification Pipeline for Drug Synergy\n",
    " - Encodes categorical features (Drug1, Drug2, Cell line)\n",
    " - Uses synergy score (ZIP) as numerical feature\n",
    " - Trains RandomForestClassifier as baseline\n",
    " - Evaluates with Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c98e5b-dea8-425c-b1bd-06b69e26b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "INPUT_PATH = Path(r\"C:\\Users\\46762\\VSCODE\\BIG_PHARMA\\data\\raw\\Syner&Antag_zip.csv\")  # <-- your CSV\n",
    "OUT_DIR    = Path(r\"C:\\Users\\46762\\VSCODE\\BIG_PHARMA\\data\\interim\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE   = 0.2\n",
    "\n",
    "# If your classification label was derived from ZIP cutoffs, keep this False to avoid trivial leakage.\n",
    "INCLUDE_ZIP_AS_FEATURE = False\n",
    "\n",
    "# Optional: run a label-shuffle sanity check to detect hidden leakage\n",
    "RUN_RANDOM_LABEL_TEST = True\n",
    "\n",
    "# =========================\n",
    "# Cleaning helpers (mirrors your style)\n",
    "# =========================\n",
    "def norm_str(x):\n",
    "    \"\"\"Normalize strings: lowercase, trim, unify dashes.\"\"\"\n",
    "    if pd.isna(x): return np.nan\n",
    "    s = str(x).strip().lower().replace(\"–\", \"-\")\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def canonicalize_pairs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pairs = df[[\"drug1\", \"drug2\"]].apply(lambda r: tuple(sorted([r[\"drug1\"], r[\"drug2\"]])), axis=1)\n",
    "    df[\"drug_min\"] = [p[0] for p in pairs]\n",
    "    df[\"drug_max\"] = [p[1] for p in pairs]\n",
    "    return df\n",
    "\n",
    "def add_label_encodings(df: pd.DataFrame) -> Tuple[pd.DataFrame, LabelEncoder, LabelEncoder]:\n",
    "    le_cell, le_drug = LabelEncoder(), LabelEncoder()\n",
    "    df[\"cell_id\"] = le_cell.fit_transform(df[\"cell_line\"])\n",
    "    all_drugs = pd.Index(df[\"drug_min\"]).append(pd.Index(df[\"drug_max\"])).unique()\n",
    "    le_drug.fit(all_drugs)\n",
    "    df[\"drug_min_id\"] = le_drug.transform(df[\"drug_min\"])\n",
    "    df[\"drug_max_id\"] = le_drug.transform(df[\"drug_max\"])\n",
    "    return df, le_cell, le_drug\n",
    "\n",
    "def add_frequency_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    dmin_freq = df[\"drug_min\"].value_counts().to_dict()\n",
    "    dmax_freq = df[\"drug_max\"].value_counts().to_dict()\n",
    "    cell_freq = df[\"cell_line\"].value_counts().to_dict()\n",
    "\n",
    "    df[\"drug_min_freq\"] = df[\"drug_min\"].map(dmin_freq)\n",
    "    df[\"drug_max_freq\"] = df[\"drug_max\"].map(dmax_freq)\n",
    "    df[\"cell_freq\"]     = df[\"cell_line\"].map(cell_freq)\n",
    "\n",
    "    for c in [\"drug_min_freq\", \"drug_max_freq\", \"cell_freq\"]:\n",
    "        df[f\"{c}_log\"] = np.log1p(df[c])\n",
    "    return df\n",
    "\n",
    "def clean_input(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load and clean the classified dataset in your style.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # --- Standardize column names ---\n",
    "    rename = {\n",
    "        \"Drug1\": \"drug1\",\n",
    "        \"Drug2\": \"drug2\",\n",
    "        \"Cell line\": \"cell_line\",\n",
    "        \"ZIP\": \"synergy_zip\",         # keep as numeric but exclude from features by default\n",
    "        \"classification\": \"label\"\n",
    "    }\n",
    "    df = df.rename(columns=rename)\n",
    "\n",
    "    # --- Normalize strings ---\n",
    "    for c in [\"drug1\", \"drug2\", \"cell_line\"]:\n",
    "        df[c] = df[c].apply(norm_str)\n",
    "\n",
    "    # --- Drop NA and self-pairs ---\n",
    "    df = df.dropna(subset=[\"drug1\", \"drug2\", \"cell_line\", \"label\"])\n",
    "    df = df[df[\"drug1\"] != df[\"drug2\"]]\n",
    "\n",
    "    # --- Canonical pair & pair_id ---\n",
    "    df = canonicalize_pairs(df)\n",
    "    df[\"pair_id\"] = df[\"drug_min\"] + \"_\" + df[\"drug_max\"]\n",
    "\n",
    "    # --- Label encodings (IDs) ---\n",
    "    df, _, _ = add_label_encodings(df)\n",
    "\n",
    "    # --- Frequency features ---\n",
    "    df = add_frequency_features(df)\n",
    "\n",
    "    # Make sure synergy_zip is numeric if present\n",
    "    if \"synergy_zip\" in df.columns:\n",
    "        df[\"synergy_zip\"] = pd.to_numeric(df[\"synergy_zip\"], errors=\"coerce\")\n",
    "\n",
    "    # Save cleaned snapshot\n",
    "    cleaned_path = OUT_DIR / \"classified_clean.csv\"\n",
    "    df.to_csv(cleaned_path, index=False)\n",
    "    print(f\"[INFO] Saved cleaned dataset → {cleaned_path} | shape={df.shape}\")\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# Feature building\n",
    "# =========================\n",
    "def build_features(df: pd.DataFrame, include_zip: bool) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:\n",
    "    \"\"\"Return X, y, groups where groups = (pair_id + cell_line) to avoid leakage.\"\"\"\n",
    "    base_cols = [\n",
    "        \"drug_min_id\", \"drug_max_id\", \"cell_id\",\n",
    "        \"drug_min_freq_log\", \"drug_max_freq_log\", \"cell_freq_log\"\n",
    "    ]\n",
    "    if include_zip and \"synergy_zip\" in df.columns:\n",
    "        base_cols.append(\"synergy_zip\")\n",
    "\n",
    "    X = df[base_cols].copy()\n",
    "    y = df[\"label\"].astype(str).copy()\n",
    "\n",
    "    # Groups to avoid leakage across (drug_min, drug_max, cell_line)\n",
    "    groups = (df[\"pair_id\"].astype(str) + \"__\" + df[\"cell_line\"].astype(str))\n",
    "    return X, y, groups\n",
    "\n",
    "# =========================\n",
    "# Train / Evaluate\n",
    "# =========================\n",
    "def train_eval_once(X, y, groups, random_state=RANDOM_SEED, test_size=TEST_SIZE) -> Dict[str, float]:\n",
    "    \"\"\"Group-aware single split eval.\"\"\"\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    tr_idx, te_idx = next(splitter.split(X, y, groups=groups))\n",
    "\n",
    "    Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "    # Strong, fast baseline\n",
    "    clf = HistGradientBoostingClassifier(\n",
    "        learning_rate=0.08,\n",
    "        max_depth=None,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=0.0,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    yhat = clf.predict(Xte)\n",
    "    yproba = None\n",
    "    try:\n",
    "        yproba = clf.predict_proba(Xte)  # may not be available for HGB in older versions\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(\"\\n=== Classification Report (Group-aware split) ===\")\n",
    "    print(classification_report(yte, yhat, digits=3))\n",
    "\n",
    "    cm = confusion_matrix(yte, yhat, labels=np.unique(y))\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "    # Compute ROC-AUC and PR-AUC for \"synergy\" class if probabilities exist and binary problem\n",
    "    metrics = {}\n",
    "    if yproba is not None and len(np.unique(y)) == 2:\n",
    "        # Map positive class as \"synergy\" if present, else use the second class lexicographically\n",
    "        classes = clf.classes_\n",
    "        pos_idx = np.where(classes == \"synergy\")[0][0] if \"synergy\" in classes else 1\n",
    "        proba_pos = yproba[:, pos_idx]\n",
    "        # Convert labels to binary for metrics\n",
    "        y_bin = (yte == classes[pos_idx]).astype(int)\n",
    "        try:\n",
    "            metrics[\"roc_auc\"] = roc_auc_score(y_bin, proba_pos)\n",
    "            metrics[\"pr_auc\"]  = average_precision_score(y_bin, proba_pos)\n",
    "            print(f\"ROC-AUC: {metrics['roc_auc']:.3f} | PR-AUC: {metrics['pr_auc']:.3f}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def group_kfold_cv(X, y, groups, n_splits=5) -> None:\n",
    "    \"\"\"Extra: GroupKFold CV for stability (no leakage).\"\"\"\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    scores = []\n",
    "    fold = 1\n",
    "    for tr_idx, te_idx in gkf.split(X, y, groups):\n",
    "        clf = HistGradientBoostingClassifier(\n",
    "            learning_rate=0.08,\n",
    "            max_depth=None,\n",
    "            max_leaf_nodes=31,\n",
    "            random_state=RANDOM_SEED + fold\n",
    "        )\n",
    "        clf.fit(X.iloc[tr_idx], y.iloc[tr_idx])\n",
    "        yhat = clf.predict(X.iloc[te_idx])\n",
    "        print(f\"\\n[Fold {fold}]\")\n",
    "        print(classification_report(y.iloc[te_idx], yhat, digits=3))\n",
    "        fold += 1\n",
    "\n",
    "def random_label_sanity_check(X, y, groups):\n",
    "    \"\"\"Shuffle labels and ensure performance collapses (detects hidden leakage).\"\"\"\n",
    "    y_rand = y.sample(frac=1.0, random_state=999).reset_index(drop=True)\n",
    "    X_rand = X.reset_index(drop=True)\n",
    "    groups_rand = groups.reset_index(drop=True)\n",
    "\n",
    "    print(\"\\n[Sanity] Training with RANDOMIZED labels...\")\n",
    "    _ = train_eval_once(X_rand, y_rand, groups_rand, random_state=777)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    df = clean_input(INPUT_PATH)\n",
    "    X, y, groups = build_features(df, include_zip=INCLUDE_ZIP_AS_FEATURE)\n",
    "\n",
    "    print(f\"[INFO] Feature matrix shape: {X.shape} | Labels: {y.value_counts().to_dict()}\")\n",
    "    print(f\"[INFO] INCLUDE_ZIP_AS_FEATURE = {INCLUDE_ZIP_AS_FEATURE}\")\n",
    "\n",
    "    # Group-aware single split eval\n",
    "    _ = train_eval_once(X, y, groups)\n",
    "\n",
    "    # Optional: GroupKFold CV for stability\n",
    "    print(\"\\n[INFO] Running GroupKFold CV (5 folds) for stability...\")\n",
    "    group_kfold_cv(X, y, groups, n_splits=5)\n",
    "\n",
    "    # Optional: randomized label test to detect leakage\n",
    "    if RUN_RANDOM_LABEL_TEST:\n",
    "        random_label_sanity_check(X, y, groups)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
